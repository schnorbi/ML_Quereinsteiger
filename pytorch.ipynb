{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = pd.read_csv('Iris.csv')\n",
    "\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_strings_to_numbers(string_list):\n",
    "    unique_strings = list(set(string_list))\n",
    "    string_to_number = {string: number for number, string in enumerate(unique_strings)}\n",
    "\n",
    "    # Ersetze die Strings durch numerische Werte\n",
    "    numerical_list = [string_to_number[string] for string in string_list]\n",
    "\n",
    "    return numerical_list, string_to_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere die Spaltennamen\n",
    "features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "lables = 'Species'\n",
    "\n",
    "# Aufteilen der Daten in Features (X) und Labels (y)\n",
    "X = iris_data[features].values\n",
    "y = iris_data[lables].values\n",
    "\n",
    "# Transformation zu Nummern\n",
    "y, string_to_number_dict = map_strings_to_numbers(y)\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testsets\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "#Aufteilen der X_Test und y_test Daten\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisieren der Daten\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Erstellen von Trainings- und Testdatens채tzen\n",
    "train_dataset = YourDataset(X_train, y_train)\n",
    "val_dataset = YourDataset(X_val, y_val)\n",
    "test_dataset = YourDataset(X_test, y_test)\n",
    "\n",
    "# Erstellen von Datenladern\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Definieren des Modells, der Verlustfunktion und des Optimierers\n",
    "input_size = 4  # Anzahl der Merkmale im Iris-Datensatz\n",
    "hidden_size = 8 # Anzahl verstecket Neuronen\n",
    "num_classes = 10  # Anzahl der Klassen \n",
    "model = SimpleNN(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2629177570343018\n",
      "Val Accuracy: 0.00%\n",
      "Epoch 2, Loss: 2.2418274879455566\n",
      "Val Accuracy: 0.00%\n",
      "Epoch 3, Loss: 2.2178642749786377\n",
      "Val Accuracy: 0.00%\n",
      "Epoch 4, Loss: 2.2434558868408203\n",
      "Val Accuracy: 3.33%\n",
      "Epoch 5, Loss: 2.21327543258667\n",
      "Val Accuracy: 3.33%\n",
      "Epoch 6, Loss: 2.0582501888275146\n",
      "Val Accuracy: 6.67%\n",
      "Epoch 7, Loss: 2.0848426818847656\n",
      "Val Accuracy: 6.67%\n",
      "Epoch 8, Loss: 2.076110363006592\n",
      "Val Accuracy: 10.00%\n",
      "Epoch 9, Loss: 1.8887815475463867\n",
      "Val Accuracy: 13.33%\n",
      "Epoch 10, Loss: 1.943354845046997\n",
      "Val Accuracy: 33.33%\n",
      "Epoch 11, Loss: 1.7898261547088623\n",
      "Val Accuracy: 33.33%\n",
      "Epoch 12, Loss: 1.878023386001587\n",
      "Val Accuracy: 40.00%\n",
      "Epoch 13, Loss: 1.738572359085083\n",
      "Val Accuracy: 60.00%\n",
      "Epoch 14, Loss: 1.717690110206604\n",
      "Val Accuracy: 76.67%\n",
      "Epoch 15, Loss: 1.774990439414978\n",
      "Val Accuracy: 83.33%\n",
      "Epoch 16, Loss: 1.7006133794784546\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 17, Loss: 1.3864047527313232\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 18, Loss: 1.4271275997161865\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 19, Loss: 1.3780293464660645\n",
      "Val Accuracy: 83.33%\n",
      "Epoch 20, Loss: 1.3966858386993408\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 21, Loss: 1.5401875972747803\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 22, Loss: 1.3720858097076416\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 23, Loss: 1.3612186908721924\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 24, Loss: 1.200395941734314\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 25, Loss: 1.2566421031951904\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 26, Loss: 1.3187988996505737\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 27, Loss: 1.0333386659622192\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 28, Loss: 1.1476269960403442\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 29, Loss: 0.9576801061630249\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 30, Loss: 1.0679714679718018\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 31, Loss: 1.2685763835906982\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 32, Loss: 0.8763060569763184\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 33, Loss: 0.8857752680778503\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 34, Loss: 1.044317603111267\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 35, Loss: 0.8321570158004761\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 36, Loss: 0.8997529149055481\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 37, Loss: 1.0030494928359985\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 38, Loss: 0.7586928606033325\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 39, Loss: 0.4924507141113281\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 40, Loss: 0.7629477977752686\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 41, Loss: 0.857308030128479\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 42, Loss: 0.732027530670166\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 43, Loss: 0.694467306137085\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 44, Loss: 0.7700033187866211\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 45, Loss: 0.6346443295478821\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 46, Loss: 0.5761494040489197\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 47, Loss: 0.4124465584754944\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 48, Loss: 0.5586014986038208\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 49, Loss: 0.5629138350486755\n",
      "Val Accuracy: 86.67%\n",
      "Epoch 50, Loss: 0.5262212753295898\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 51, Loss: 0.7434960603713989\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 52, Loss: 0.7347186803817749\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 53, Loss: 0.7031524777412415\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 54, Loss: 0.526075541973114\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 55, Loss: 0.6636249423027039\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 56, Loss: 0.5792363882064819\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 57, Loss: 0.6837838888168335\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 58, Loss: 0.6503211259841919\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 59, Loss: 0.37534239888191223\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 60, Loss: 0.6523264646530151\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 61, Loss: 0.33520394563674927\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 62, Loss: 0.34389644861221313\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 63, Loss: 0.6918045878410339\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 64, Loss: 0.550014853477478\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 65, Loss: 0.6668466329574585\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 66, Loss: 0.5288903117179871\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 67, Loss: 0.32160425186157227\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 68, Loss: 0.6240516901016235\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 69, Loss: 0.5963282585144043\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 70, Loss: 0.4331858158111572\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 71, Loss: 0.5977362394332886\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 72, Loss: 0.4479077458381653\n",
      "Val Accuracy: 90.00%\n",
      "Epoch 73, Loss: 0.5891585946083069\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 74, Loss: 0.29317212104797363\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 75, Loss: 0.5456804037094116\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 76, Loss: 0.3887045085430145\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 77, Loss: 0.6123029589653015\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 78, Loss: 0.4770810604095459\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 79, Loss: 0.43731385469436646\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 80, Loss: 0.4099711775779724\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 81, Loss: 0.48699989914894104\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 82, Loss: 0.342599093914032\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 83, Loss: 0.4622473120689392\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 84, Loss: 0.28864941000938416\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 85, Loss: 0.5429158210754395\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 86, Loss: 0.2254341095685959\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 87, Loss: 0.3725890517234802\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 88, Loss: 0.39899444580078125\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 89, Loss: 0.5693095922470093\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 90, Loss: 0.5013104677200317\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 91, Loss: 0.47784239053726196\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 92, Loss: 0.3850361704826355\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 93, Loss: 0.4172542691230774\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 94, Loss: 0.34774309396743774\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 95, Loss: 0.2520137429237366\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 96, Loss: 0.34362393617630005\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 97, Loss: 0.3277047276496887\n",
      "Val Accuracy: 93.33%\n",
      "Epoch 98, Loss: 0.3954906165599823\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 99, Loss: 0.28926882147789\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 100, Loss: 0.43494755029678345\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 101, Loss: 0.413013219833374\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 102, Loss: 0.4845546782016754\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 103, Loss: 0.3675640821456909\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 104, Loss: 0.4940846860408783\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 105, Loss: 0.17406347393989563\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 106, Loss: 0.5255783796310425\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 107, Loss: 0.3449426293373108\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 108, Loss: 0.34117648005485535\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 109, Loss: 0.3366698622703552\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 110, Loss: 0.281375527381897\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 111, Loss: 0.2389594316482544\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 112, Loss: 0.40970128774642944\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 113, Loss: 0.4645613133907318\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 114, Loss: 0.34682586789131165\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 115, Loss: 0.1919616460800171\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 116, Loss: 0.17033037543296814\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 117, Loss: 0.37172967195510864\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 118, Loss: 0.20269496738910675\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 119, Loss: 0.31757354736328125\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 120, Loss: 0.23234272003173828\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 121, Loss: 0.2752653956413269\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 122, Loss: 0.272726446390152\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 123, Loss: 0.25207775831222534\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 124, Loss: 0.36670106649398804\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 125, Loss: 0.36871451139450073\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 126, Loss: 0.28500813245773315\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 127, Loss: 0.1977781504392624\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 128, Loss: 0.2235870361328125\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 129, Loss: 0.3522857129573822\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 130, Loss: 0.24958951771259308\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 131, Loss: 0.28614717721939087\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 132, Loss: 0.4591764807701111\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 133, Loss: 0.18532823026180267\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 134, Loss: 0.23103995621204376\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 135, Loss: 0.21922269463539124\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 136, Loss: 0.23161952197551727\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 137, Loss: 0.17508792877197266\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 138, Loss: 0.23746363818645477\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 139, Loss: 0.2334514856338501\n",
      "Val Accuracy: 96.67%\n",
      "Epoch 140, Loss: 0.22446174919605255\n",
      "Val Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 0\n",
    "accuracy = 0\n",
    "\n",
    "while accuracy != 1.0:\n",
    "    num_epochs += 1\n",
    "    for inputs, labels in train_loader:\n",
    "        # Vorw채rtsdurchlauf\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # R체ckw채rtsdurchlauf und Optimierung\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Val Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-virginica',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-setosa',\n",
       " 'Iris-virginica',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-virginica',\n",
       " 'Iris-setosa',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-virginica',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-setosa']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "def map_numbers_to_strings(numerical_list, string_to_number_dict):\n",
    "    # Umkehren des Mappings\n",
    "    number_to_string_dict = {number: string for string, number in string_to_number_dict.items()}\n",
    "\n",
    "    # Ersetze numerische Werte durch Strings\n",
    "    original_strings = [number_to_string_dict[number] for number in numerical_list]\n",
    "\n",
    "    return original_strings\n",
    "\n",
    "\n",
    "map_numbers_to_strings(predicted.tolist(), string_to_number_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
